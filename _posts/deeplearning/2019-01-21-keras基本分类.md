---
categories: [深度学习]
tags: [Keras, 基本分类, matplotlib]
---
最近几天不怎么想学习，看了些电视剧。做个自我检讨，感觉浪费时间挺可耻的，对于自己来说，如何让自己一直保持一种高度想要获取知识的心态，并自觉的进行不断的学习，真的是一件不容易的事。这个需要自己以后继续不断思索，反正这次是铁了心，一定要坚持下去。翻了些资料粗略看过后，又打开了tensorflow官网，开始看学习教程，然后自己跟着把代码copy到自己机器里，并不断的修改，查看结果，也学到了些皮毛，发现了很多不懂得东西，特此记录。
# 入门例子
```
(venv) xianfa@xianfa:~/machinelearning/study$ cat kerassimple.py 
import tensorflow as tf
mnist = tf.keras.datasets.mnist

(x_train, y_train),(x_test, y_test) = mnist.load_data()
x_train, x_test = x_train / 255.0, x_test / 255.0

model = tf.keras.models.Sequential([
    tf.keras.layers.Flatten(),
    tf.keras.layers.Dense(512,activation=tf.nn.relu),
    tf.keras.layers.Dropout(0.2),
    tf.keras.layers.Dense(10, activation=tf.nn.softmax)
    ])
model.compile(optimizer='adam',
        loss='sparse_categorical_crossentropy',
        metrics=['accuracy'])

model.fit(x_train, y_train, epochs=1)
model.evaluate(x_test, y_test)
```
# 源码分析
只要用心，处处是知识。虽然我不理解具体得执行的详细细节，但根据前面的回归分析，再加上这个例子，就可以总结出机器学习的基本程序结构，及数据准备，训练模型，验证以及新数据预测。我这里只记录下我的疑问，这些都搞明白的话，深度学习也就完成了。mnist数据是如何建立的？我猜想是手工的，如果是手工建立的，那么有没有使用程序自动建立数据的方法？数据是多样的，机器建立必然会有各种错误数据，或者含糊的数据，如何处理？我是python初学者，mnist.load_data()的返回值如何解释？另外这里的数据必然是从网络上传递的，实现的具体过程，socket？http？网络断线后，恢复正常，能否继续下载，是否支持端点续传？学到网络上去了，不再追究。后面的问题继续。显然这里是把训练和测试数据，转换到了[0,1],为什么？后面的调用问题就更多了，model定义部分来看明显是个神经网络，除了Squqential还有那些？该例子中是几层的神经网络，每层的作用是什么?activation是什么,本例子所给出的两个作用是什么,有什么差别？tf.keras.layers.Dense(512,activation=tf.nn.relu)里面512代表什么？为什么取该值？Dropout应该是防止过拟合的，这里面也有很多需要学习，好吧，继续往下，compile里面的参数代表什么含义，虽然看了文档依然不太理解，只怪自己太菜，后面代码比较明显，fit就是按前面的模型训练，evaluate就是用测试数据评估。这里面原来的例子中epochs=5，我考虑执行时间改为1，这里的疑问是epochs显然不是越大越好，多少合适？
```
(venv) xianfa@xianfa:~/machinelearning/study$ python kerassimple.py 
Epoch 1/1
2019-01-21 03:02:36.855468: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2
60000/60000 [==============================] - 13s 218us/step - loss: 0.2026 - acc: 0.9390
10000/10000 [==============================] - 0s 50us/step
```
以上为执行结果，从结果来看，训练的结果还是比较清晰的，evaluate的结果就不知道是什么了，虽然很多不明白，但从程序上来看，该代码真的很简洁，下面开始学习手册里面的基本分类。
# 基本分类源码
```
(venv) xianfa@xianfa:~/machinelearning/study$ cat kerasbasicclassification.py 
# TensorFlow and tf.keras
import tensorflow as tf
from tensorflow import keras

# Helper libraries
import numpy as np
import matplotlib
matplotlib.use('Agg')
import matplotlib.pyplot as plt

def saveimg(imagearray, index):
    plt.figure()
    plt.imshow(imagearray[index])
    plt.colorbar()
    plt.grid(False)
    plt.savefig('./test' + str(index) + '.jpg')

def saveimgs(imgwidth, imgheight, subrows, subcols, imagearray, labelindexarray, labels, savefilename):
    plt.figure(figsize=(imgwidth, imgheight))
    for i in range(subrows*subcols):
        plt.subplot(subrows, subcols, i+1)
        plt.xticks([])
        plt.yticks([])
        plt.grid(False)
        plt.imshow(imagearray[i], cmap=plt.cm.binary)
        plt.xlabel(labels[labelindexarray[i]])
        plt.savefig(savefilename)

def plot_image(i, predictions_array, true_label, img):
    predictions_array, true_label, img = predictions_array[i], true_label[i], img[i]
    plt.grid(False)
    plt.xticks([])
    plt.yticks([])

    plt.imshow(img, cmap=plt.cm.binary)

    predicted_label = np.argmax(predictions_array)
    if predicted_label == true_label:
        color = 'blue'
    else:
        color = 'red'
    plt.xlabel("{} {:2.0f}% ({})".format(class_names[predicted_label],
        100*np.max(predictions_array),
        class_names[true_label]),
        color=color)

def plot_value_array(i, predictions_array, true_label):
    predictions_array, true_label = predictions_array[i], true_label[i]
    plt.grid(False)
    plt.xticks([])
    plt.yticks([])
    thisplot = plt.bar(range(10), predictions_array, color="#777777")
    plt.ylim([0, 1])
    predicted_label = np.argmax(predictions_array)

    thisplot[predicted_label].set_color('red')
    thisplot[true_label].set_color('blue')

def savesingleprediction(index, images, labels, predictions):
    plt.figure(figsize=(6,3))
    plt.subplot(1,2,1)
    plot_image(index, predictions, labels, images)
    plt.subplot(1,2,2)
    plot_value_array(index, predictions,  labels)
    plt.savefig('prediction' + str(index) + '.jpg')

def savepredictions(num_rows, num_cols, images, labels, predictions, savefilename):
    num_images = num_rows*num_cols
    plt.figure(figsize=(2*2*num_cols, 2*num_rows))
    for i in range(num_images):
        plt.subplot(num_rows, 2*num_cols, 2*i+1)
        plot_image(i, predictions, labels, images)
        plt.subplot(num_rows, 2*num_cols, 2*i+2)
        plot_value_array(i, predictions, labels)
    plt.savefig(savefilename)

if __name__ == '__main__':
    #get data
    fashion_mnist = keras.datasets.fashion_mnist
    (train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()
    class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']

    #save a train image
    for i in range(1):
        saveimg(train_images, i)

    #change value to range [0, 1]
    train_images = train_images / 255.0
    test_images = test_images / 255.0

    #save train images
    saveimgs(10, 10, 5, 5, train_images, train_labels, class_names, 'first25.jpg')

    #neural network training
    model = keras.Sequential([
            keras.layers.Flatten(input_shape=(28, 28)),
            keras.layers.Dense(128, activation=tf.nn.relu),
            keras.layers.Dense(10, activation=tf.nn.softmax)
            ])
    model.compile(optimizer=tf.train.AdamOptimizer(),
            loss='sparse_categorical_crossentropy',
            metrics=['accuracy'])
    model.fit(train_images, train_labels, epochs=1)

    #use test data to test
    test_loss, test_acc = model.evaluate(test_images, test_labels)
    print('Test accuracy:', test_acc)

    #use test data to predict
    predictions = model.predict(test_images)

    #save predict result and check it
    savesingleprediction(5, test_images, test_labels, predictions)
    savesingleprediction(12, test_images, test_labels, predictions)
    savepredictions(5, 3, test_images, test_labels, predictions, 'predictiontotal.jpg')

    #predict single one example
    img = test_images[0]
    img = (np.expand_dims(img,0))

    #predict result
    predictions_single = model.predict(img)

    #save file to check
    savesingleprediction(0, test_images, test_labels, predictions_single)
```
# 源码分析
执行结果
```
(venv) xianfa@xianfa:~/machinelearning/study$ python kerasbasicclassification.py 
Epoch 1/1
2019-01-21 03:22:44.759966: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2
60000/60000 [==============================] - 3s 55us/step - loss: 0.5053 - acc: 0.8221
10000/10000 [==============================] - 0s 29us/step
Test accuracy: 0.8459
```
这是控制台输出的结果，另外还生成了几张jpg文件，这个例子差不多可以认为是前面入门例子的展开。我在这里学到主要是利用matplotlib进行一些可视化的展示，方便理解。

![基础数据](../../../screenshot/machinelearning/2019-01-21/test0.jpg "训练测试数据")  
上图为一个训练测试数据实例，是一个28*28的图片，像素取值范围为0-255之间。  
![前25个训练数据](../../../screenshot/machinelearning/2019-01-21/first25.jpg "前25个训练数据")  
上图为将训练数据像素变换为0-1之间后，前25个训练数据，也就是28*28黑白图像的黑白图像，以及该图像所代表衣服的类别。  
![单个预测结果](../../../screenshot/machinelearning/2019-01-21/prediction5.jpg "单个预测结果")  
上图为一个预测结果，左边为所预测的图形，及最后预测的分类结果，右边是预测各个分类的概率。  
![预测结果列表](../../../screenshot/machinelearning/2019-01-21/predictionlist.jpg "预测结果列表")  
上图为一个预测结果列表，这里红色代表预测错误，蓝色代表实际类别。  
真的是几张图说明了所有问题，mnist就是一个衣服图像及其类别的一个数据集。这个例子就是直接根据训练数据里面的已知数据，然后根据神经网络训练出模型参数，然后使用测试数据进行预测的一个实例，非常形象的一个分类预测问题。

# 学习总结
学到了在markdown中插入图片，学会了keras基本分类的处理步骤与方法，但同时发现里面有更多的东西需要学习。检讨了自己没有坚持学习的问题，并会想法设法保持继续学习的积极性与自觉性。虽然只是一个简单的小例子，感觉很充实，加油！